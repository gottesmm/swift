// RUN: %target-sil-opt -transfer-non-sendable -enable-upcoming-feature RegionBasedIsolation -strict-concurrency=complete %s -o /dev/null -verify

// REQUIRES: concurrency
// REQUIRES: asserts

// PLEASE READ THIS!
//
// This test is specifically meant for small test cases that come from bugs that
// do not categorize by a specific category. If this gets too big, please split
// sections of tests out if possible.

sil_stage raw

import Swift
import Builtin

////////////////////////
// MARK: Declarations //
////////////////////////

class NonSendableKlass {}

sil @transferNonSendableKlass : $@convention(thin) @async (@guaranteed NonSendableKlass) -> ()
sil @useNonSendableKlass : $@convention(thin) (@guaranteed NonSendableKlass) -> ()
sil @constructNonSendableKlass : $@convention(thin) () -> @owned NonSendableKlass
sil @useUnmanagedNonSendableKlass : $@convention(thin) (@guaranteed @sil_unmanaged NonSendableKlass) -> ()

final class SendableKlass : Sendable {}

sil @transferSendableKlass : $@convention(thin) @async (@guaranteed SendableKlass) -> ()
sil @constructSendableKlass : $@convention(thin) () -> @owned SendableKlass

final class KlassContainingKlasses {
  let nsImmutable : NonSendableKlass
  var nsMutable : NonSendableKlass
  let sImmutable : SendableKlass
  var sMutable : SendableKlass
}

sil @transferKlassContainingKlasses : $@convention(thin) @async (@guaranteed KlassContainingKlasses) -> ()
sil @useKlassContainingKlasses : $@convention(thin) (@guaranteed KlassContainingKlasses) -> ()
sil @constructKlassContainingKlasses : $@convention(thin) () -> @owned KlassContainingKlasses

@_moveOnly
struct NonSendableMoveOnlyStruct {
  var ns: NonSendableKlass

  deinit
}

sil @constructMoveOnlyStruct : $@convention(thin) () -> @owned NonSendableMoveOnlyStruct
sil @transferMoveOnlyStruct : $@convention(thin) @async (@guaranteed NonSendableMoveOnlyStruct) -> ()

struct NonSendableStruct {
  var ns: NonSendableKlass
}

sil @constructStruct : $@convention(thin) () -> @owned NonSendableStruct
sil @transferStruct : $@convention(thin) @async (@guaranteed NonSendableStruct) -> ()

sil @transferRawPointer : $@convention(thin) @async (Builtin.RawPointer) -> ()
sil @useRawPointer : $@convention(thin) (Builtin.RawPointer) -> ()
sil @initRawPointer : $@convention(thin) () -> Builtin.RawPointer

sil @transferIndirect : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> ()
sil @transferIndirectWithOutResult : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> @out τ_0_0
sil @useIndirect : $@convention(thin) <τ_0_0> (@in_guaranteed τ_0_0) -> ()
sil @initIndirect : $@convention(thin) <T> () -> @out T
sil @initIndirectTransferring : $@convention(thin) @async <T> () -> @out T
sil @initIndirectTransferringError : $@convention(thin) @async <T> () -> (@out Optional<T>, @error any Error)

enum FakeOptional<T> {
case none
case some(T)
}

sil @swift_asyncLet_get : $@convention(thin) @async (Builtin.RawPointer, Builtin.RawPointer) -> ()
sil @swift_asyncLet_finish : $@convention(thin) @async (Builtin.RawPointer, Builtin.RawPointer) -> ()

/////////////////
// MARK: Tests //
/////////////////

// This goes through the access projection code differently from normal
// project_box since we do not see the alloc_box.
sil [ossa] @project_box_loadable_test_case : $@convention(thin) @async (@in { var NonSendableKlass }) -> () {
bb0(%0 : $*{ var NonSendableKlass }):
  %1 = load [take] %0 : $*{ var NonSendableKlass }
  %3 = project_box %1 : ${ var NonSendableKlass }, 0

  %f = function_ref @transferIndirect : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> ()
  apply [caller_isolation=nonisolated] [callee_isolation=global_actor] %f<NonSendableKlass>(%3) : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> ()
  // expected-warning @-1 {{task isolated value of type 'NonSendableKlass' transferred to global actor '<null>'-isolated context}}
  destroy_value %1 : ${ var NonSendableKlass }

  %9999 = tuple ()
  return %9999 : $()
}

// This doesn't error since the @out parameter is not transferred when it is initialized.
//
// DISCUSSION: The frontend prevents us from using such a value. But we
// shouldn't crash on such values.
sil [ossa] @transfer_does_not_transfer_out_parameters_1 : $@convention(thin) @async () -> () {
bb0:
  %0 = alloc_stack $NonSendableKlass
  %init = function_ref @initIndirect : $@convention(thin) <T> () -> @out T
  apply %init<NonSendableKlass>(%0) : $@convention(thin) <T> () -> @out T

  %1 = alloc_stack $NonSendableKlass
  %f = function_ref @transferIndirectWithOutResult : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> @out τ_0_0
  apply [caller_isolation=nonisolated] [callee_isolation=global_actor] %f<NonSendableKlass>(%1, %0) : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> @out τ_0_0

  %useIndirect = function_ref @useIndirect : $@convention(thin) <τ_0_0> (@in_guaranteed τ_0_0) -> ()
  apply %useIndirect<NonSendableKlass>(%1) : $@convention(thin) <τ_0_0> (@in_guaranteed τ_0_0) -> ()

  destroy_addr %1 : $*NonSendableKlass
  dealloc_stack %1 : $*NonSendableKlass
  destroy_addr %0 : $*NonSendableKlass
  dealloc_stack %0 : $*NonSendableKlass

  %9999 = tuple ()
  return %9999 : $()
}

sil [ossa] @transfer_does_not_transfer_out_parameters_2 : $@convention(thin) @async () -> () {
bb0:
  %0 = alloc_stack $NonSendableKlass
  %init = function_ref @initIndirect : $@convention(thin) <T> () -> @out T
  apply %init<NonSendableKlass>(%0) : $@convention(thin) <T> () -> @out T

  %1 = alloc_stack $NonSendableKlass
  %f = function_ref @transferIndirectWithOutResult : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> @out τ_0_0
  apply [caller_isolation=nonisolated] [callee_isolation=global_actor] %f<NonSendableKlass>(%1, %0) : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> @out τ_0_0

  %f2 = function_ref @transferIndirect : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> ()
  apply [caller_isolation=nonisolated] [callee_isolation=global_actor] %f2<NonSendableKlass>(%1) : $@convention(thin) @async <τ_0_0> (@in_guaranteed τ_0_0) -> ()
  // expected-warning @-1 {{transferring value of non-Sendable type 'NonSendableKlass' from nonisolated context to global actor '<null>'-isolated context}}
  %useIndirect = function_ref @useIndirect : $@convention(thin) <τ_0_0> (@in_guaranteed τ_0_0) -> ()
  apply %useIndirect<NonSendableKlass>(%1) : $@convention(thin) <τ_0_0> (@in_guaranteed τ_0_0) -> ()
  // expected-note @-1 {{access here could race}}

  destroy_addr %1 : $*NonSendableKlass
  dealloc_stack %1 : $*NonSendableKlass
  destroy_addr %0 : $*NonSendableKlass
  dealloc_stack %0 : $*NonSendableKlass

  %9999 = tuple ()
  return %9999 : $()
}

sil @implicitClosure : $@convention(thin) @Sendable @async @substituted <τ_0_0> () -> (@out τ_0_0, @error any Error) for <NonSendableKlass>

sil [ossa] @asyncLetWithThinToThickFunction : $@convention(thin) @async () -> () {
bb0:
  %0 = enum $Optional<Builtin.Executor>, #Optional.none!enumelt
  hop_to_executor %0 : $Optional<Builtin.Executor>
  %2 = alloc_stack $NonSendableKlass
  %3 = address_to_pointer %2 : $*NonSendableKlass to $Builtin.RawPointer
  %4 = enum $Optional<Builtin.RawPointer>, #Optional.none!enumelt
  %5 = function_ref @implicitClosure : $@convention(thin) @Sendable @async @substituted <τ_0_0> () -> (@out τ_0_0, @error any Error) for <NonSendableKlass>
  %6 = convert_function %5 : $@convention(thin) @Sendable @async @substituted <τ_0_0> () -> (@out τ_0_0, @error any Error) for <NonSendableKlass> to $@convention(thin) @async @substituted <τ_0_0> () -> (@out τ_0_0, @error any Error) for <NonSendableKlass>
  %7 = thin_to_thick_function %6 : $@convention(thin) @async @substituted <τ_0_0> () -> (@out τ_0_0, @error any Error) for <NonSendableKlass> to $@noescape @async @callee_guaranteed @substituted <τ_0_0> () -> (@out τ_0_0, @error any Error) for <NonSendableKlass>
  %8 = builtin "startAsyncLetWithLocalBuffer"<NonSendableKlass>(%4 : $Optional<Builtin.RawPointer>, %7 : $@noescape @async @callee_guaranteed @substituted <τ_0_0> () -> (@out τ_0_0, @error any Error) for <NonSendableKlass>, %3 : $Builtin.RawPointer) : $Builtin.RawPointer
  %9 = function_ref @swift_asyncLet_get : $@convention(thin) @async (Builtin.RawPointer, Builtin.RawPointer) -> ()
  %10 = apply %9(%8, %3) : $@convention(thin) @async (Builtin.RawPointer, Builtin.RawPointer) -> ()
  hop_to_executor %0 : $Optional<Builtin.Executor>
  %12 = load [copy] %2 : $*NonSendableKlass
  destroy_value %12 : $NonSendableKlass
  %14 = function_ref @swift_asyncLet_finish : $@convention(thin) @async (Builtin.RawPointer, Builtin.RawPointer) -> ()
  %15 = apply %14(%8, %3) : $@convention(thin) @async (Builtin.RawPointer, Builtin.RawPointer) -> ()
  hop_to_executor %0 : $Optional<Builtin.Executor>
  %17 = builtin "endAsyncLetLifetime"(%8 : $Builtin.RawPointer) : $()
  dealloc_stack %2 : $*NonSendableKlass
  %19 = tuple ()
  return %19 : $()
}

// Dead block crasher
//
// We used to crash here since we attempted to process /all/ blocks for
// diagnostic even for non-dead blocks. This is a problem since the dataflow
// uses a reverse post order traversal to get quick convergence and that skips
// dead blocks.
sil [ossa] @dead_block_crasher : $@convention(thin) @async () -> () {
bb0:
  %0 = function_ref @constructNonSendableKlass : $@convention(thin) () -> @owned NonSendableKlass
  %1 = apply %0() : $@convention(thin) () -> @owned NonSendableKlass
  br bb1

bbDeadBlock:
  %transfer = function_ref @transferNonSendableKlass : $@convention(thin) @async (@guaranteed NonSendableKlass) -> ()
  apply [caller_isolation=nonisolated] [callee_isolation=global_actor] %transfer(%1) : $@convention(thin) @async (@guaranteed NonSendableKlass) -> ()
  br bb1

bb1:
  destroy_value %1 : $NonSendableKlass
  %9999 = tuple ()
  return %9999 : $()
}

